{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 필요한 라이브러리 불러오기"
      ],
      "metadata": {
        "id": "tifBTrjWyP48"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S85DqdTrxipF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "device = 'cuda'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터셋(Dataset) 다운로드 및 불러오기"
      ],
      "metadata": {
        "id": "hULuwtHpyVJ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "# 일반적으로 많이 사용되는 입력 전처리(preprocessing) 테크닉\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4), # 패딩 이후 랜덤하게 잘라서 뽑기\n",
        "    transforms.RandomHorizontalFlip(), # 좌우 반전 (MNIST 말고 CIFAR10에서는 효과적)\n",
        "    transforms.ToTensor(),\n",
        "    normalize, # 실험 결과, 입력 정규화(input normalization)가 성능에 크게 영향을 미치지는 않음\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9jdNl-XyUER",
        "outputId": "ade32f51-87ec-492d-ae2f-1441c63074d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:07<00:00, 24002139.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서 mean과 std는 각각 평균과 표준편차를 나타내며, 각 값은 RGB 채널에 대응됩니다.\n",
        "\n",
        "\n",
        "R 채널의 평균: 0.485, 표준편차: 0.229\n",
        "\n",
        "\n",
        "G 채널의 평균: 0.456, 표준편차: 0.224\n",
        "\n",
        "\n",
        "B 채널의 평균: 0.406, 표준편차: 0.225\n",
        "\n",
        "\n",
        "이 값들은 ImageNet 데이터셋에서 학습된 모델들을 위한 일반적인 평균 및 표준편차 값입니다. CIFAR-10과 같은 다른 데이터셋에 대해서도 이 값을 사용하는 것이 일반적입니다, 왜냐하면 많은 사전 학습된 모델들이 이러한 값으로 정규화된 데이터에 대해 학습되었기 때문입니다.\n",
        "\n",
        "\n",
        "정규화를 수행하는 이유는 다음과 같습니다:\n",
        "- 수렴 속도 개선: 정규화된 입력은 학습 알고리즘이 더 빠르게 수렴하도록 도와줍니다.\n",
        "- 가중치 초기화: 정규화된 입력은 가중치 초기화에 덜 민감하게 만들어줍니다.\n",
        "- 옵티마이저 최적화: 정규화는 옵티마이저가 더 효율적으로 최적화를 수행하도록 도와줍니다.\n",
        "\n",
        "\n",
        "이러한 이유로, 정규화는 딥러닝에서 이미지 데이터를 처리할 때 거의 항상 사용되는 전처리 단계입니다. - GPT"
      ],
      "metadata": {
        "id": "RF17IFFjzxop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(net, epoch, optimizer, criterion, train_loader):\n",
        "  print('[Train epoch : %d]' % epoch )\n",
        "  net.train()\n",
        "  train_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    benign_outputs = net(inputs)\n",
        "    loss = criterion(benign_outputs, targets)\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()\n",
        "    _, predicted = benign_outputs.max(1)\n",
        "\n",
        "    total += targets.size(0)\n",
        "    correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "  print('Train accuarcy:', 100. * correct / total)\n",
        "  print('Train average loss:', train_loss / total)\n",
        "  return (100. * correct / total, train_loss / total)\n",
        "\n",
        "def evaluate(net, epoch, file_name, data_loader, info):\n",
        "    print('[ Evaluate epoch: %d ]' % epoch)\n",
        "    print(\"Dataset:\", info)\n",
        "\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        total += targets.size(0)\n",
        "\n",
        "        outputs = net(inputs)\n",
        "        test_loss += criterion(outputs, targets).item()\n",
        "\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    print('Accuarcy:', 100. * correct / total)\n",
        "    print('Average loss:', test_loss / total)\n",
        "    return (100. * correct / total, test_loss / total)"
      ],
      "metadata": {
        "id": "2HtZSGVKzrvG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix 정의"
      ],
      "metadata": {
        "id": "8z_ROKAC2v4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_confusion_matrix(net, num_classes, data_loader):\n",
        "  confusion_matrix = torch.zeros(num_classes, num_classes)\n",
        "\n",
        "  net.eval()\n",
        "\n",
        "  for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "    inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "    outputs = net(inputs)\n",
        "    _, predicted = outputs.max(1)\n",
        "\n",
        "    for t, p in zip(targets.view(-1), predicted.view(-1)):\n",
        "      confusion_matrix[t.long(), p.long()] += 1\n",
        "\n",
        "  return confusion_matrix"
      ],
      "metadata": {
        "id": "yWo2eZMD2D4y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet 모델 정의\n",
        "\n",
        "- ResNet 논문에서 제안된 CIFAR-10 전용 아키텍처를 따릅니다.\n",
        "- CIFAR-10 데이터셋을 위한 아키텍처의 파라미터가 훨씬 적습니다.\n",
        "- ImageNet 데이터셋을 위한 아키텍처와는 차이가 있습니다."
      ],
      "metadata": {
        "id": "bjQCA1pw3jAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LambdaLayer(nn.Module):\n",
        "  def __init__(self, lambd):\n",
        "    super(LambdaLayer, self).__init__()\n",
        "    self.lambd = lambd\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.lambd(x)\n",
        "\n",
        "#ResNet을 위한 BasicBlock 클래스 정의\n",
        "class BasicBlock(nn.Module):\n",
        "  def __init__(self, in_planes, planes, stride=1):\n",
        "    super(BasicBlock, self).__init__()\n",
        "\n",
        "    #3x3 필터를 사용(너비와 높이를 줄일때는 stride 값 조절)\n",
        "    self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        ""
      ],
      "metadata": {
        "id": "wqi0k6zt3Zi2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}